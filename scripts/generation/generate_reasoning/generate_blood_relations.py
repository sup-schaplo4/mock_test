"""
Blood Relations Question Generator
Generates questions using OpenAI API in batches
"""

import os
import time
from datetime import datetime
from openai_utils import create_openai_client, generate_questions_openai, test_openai_connection
from utils import (
    calculate_batch_distribution,
    validate_json_output,
    save_to_json,
    log_error,
    calculate_cost,
    get_timestamp_filename
)


# ============================================================================
# CONFIGURATION - MODIFY THESE VALUES
# ============================================================================

# OpenAI API Configuration
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    raise ValueError("‚ùå Please set OPENAI_API_KEY environment variable")
MODEL_NAME = "gpt-4o"

# Question Generation Configuration
TOTAL_QUESTIONS = 30

# Difficulty Distribution (percentage-based)
DIFFICULTY_WEIGHTS = {
    "Easy": 20,      # 20% = 6 questions
    "Medium": 40,    # 40% = 12 questions
    "Hard": 40       # 40% = 12 questions
}

# Batch Configuration
BATCH_SIZE = 5
MAX_RETRIES_PER_BATCH = 3

# API Parameters
TEMPERATURE = 0.9
MAX_TOKENS = 8192

# Cost Configuration (GPT-4o pricing per million tokens)
INPUT_COST_PER_MILLION = 2.50
OUTPUT_COST_PER_MILLION = 10.00

# Output Configuration
OUTPUT_BASE_DIR = "data/generated"

# Question Metadata
TOPIC_NAME = "Blood Relations"
REASONING_TOPIC = "Blood Relations"
MAIN_CATEGORY = "Verbal & Logical Reasoning"
SUBJECT = "Reasoning"
EXAM_NAME = "RBI Grade B Phase 1"

# ============================================================================
# PROMPT TEMPLATE (Under 80 lines)
# ============================================================================

PROMPT_TEMPLATE = """# TASK: BLOOD RELATIONS QUESTION GENERATOR

## CONTEXT
You are an expert in logical reasoning and family relationship analysis, tasked with creating high-quality Blood Relations questions. These questions test the ability to trace family relationships through multiple connections, decode relationship statements, and determine how individuals are related.

## YOUR TASK
Please generate {batch_size} Blood Relations questions.

**Key Guidelines for Logical Consistency:**
As an expert in family relationship puzzles, your primary goal is to ensure every relationship chain is logically consistent and unambiguous. Please follow this internal verification process for each question you create:
1. First, construct a clear family tree or relationship chain ensuring all stated relationships are possible and consistent.
2. Second, trace the relationship from the reference person to the target person step-by-step to verify accuracy.
3. Finally, confirm that the correct answer matches the derived relationship and no alternative interpretation exists.
4. Please ensure all generated relationship puzzles are logically consistent, have unique solutions, and respect family structure rules (gender-specific relations, generation levels, etc.).

## DIFFICULTY DISTRIBUTION
Please generate the following distribution:
- {easy_count} Easy question(s)
- {medium_count} Medium question(s)
- {hard_count} Hard question(s)

Total: {batch_size} questions

## DIFFICULTY PARAMETERS

### EASY
**Relationship Structure:**
- 2-3 direct relationship statements
- Single-chain relationships (A‚ÜíB‚ÜíC)
- Clear and direct connections
- Common relationships: father, mother, son, daughter, brother, sister, grandfather, grandmother
- No ambiguous pronouns or complex descriptions
- Straightforward question: "How is X related to Y?"

### MEDIUM
**Relationship Structure:**
- 3-5 relationship statements with some indirect connections
- Multi-chain relationships with 1-2 branches
- Mix of direct and possessive relationships (e.g., "brother's wife", "son's daughter")
- May include aunts, uncles, cousins, in-laws (simple cases)
- Some coded or indirect language (e.g., "only son", "my father's son")
- Question may ask for reverse relationship or involve additional deduction

### HARD
**Relationship Structure:**
- 5-7 complex relationship statements
- Multi-generational chains (3+ generations)
- Complex branching family trees with multiple siblings/marriages
- Coded language, pronouns requiring careful interpretation, or negative statements ("has no brothers")
- In-law relationships, step-relations, or extended family (nephews, nieces, cousins multiple times removed)
- May involve puzzle elements: photographs, pointing scenarios, or conditional information
- Questions requiring multi-step logical deduction or comprehensive family tree construction

## RELATIONSHIP TYPES (Use variety across questions)
**Direct Relations:**
- Parent-child: father, mother, son, daughter
- Siblings: brother, sister
- Grandparents: grandfather, grandmother, grandson, granddaughter

**Extended Relations:**
- Aunts/Uncles: paternal/maternal aunt, paternal/maternal uncle
- Nieces/Nephews: niece, nephew
- Cousins: cousin, cousin brother, cousin sister

**In-Law Relations:**
- Spouse: husband, wife
- Parents-in-law: father-in-law, mother-in-law, son-in-law, daughter-in-law
- Siblings-in-law: brother-in-law, sister-in-law

**Complex Relations:**
- Great-grandparents, great-grandchildren
- Grand-niece, grand-nephew
- Step-relations

## QUESTION FORMATS (Use variety)
- Direct statement: "A is the father of B. B is the brother of C. How is A related to C?"
- Coded language: "Pointing to a person, X says: 'He is the son of my father's only son.' How is that person related to X?"
- Multiple chains: Complex multi-person relationship networks
- Photograph-based: "Looking at a photograph, A says..."
- Puzzle-based: "In a family of 6 members..." with conditional clues

## QUESTION ID FORMAT
Use this format for question IDs:
- blood_relations_001
- blood_relations_002
- And so on...

Start from ID: blood_relations_{start_id:03d}

## OUTPUT FORMAT
Please return a valid JSON object with a "questions" array. Structure:

{{
  "questions": [
    {{
      "question_id": "blood_relations_001",
      "question": "[Relationship statements + Question asking how X is related to Y]",
      "options": {{
        "A": "[Option A text]",
        "B": "[Option B text]",
        "C": "[Option C text]",
        "D": "[Option D text]",
        "E": "[Option E text]"
      }},
      "correct_answer": "A",
      "explanation": "[Detailed step-by-step relationship tracing showing the family connections and final relationship]",
      "difficulty": "Easy",
      "topic": "{topic}",
      "reasoning_topic": "{reasoning_topic}",
      "main_category": "{main_category}",
      "subject": "{subject}",
      "exam": "{exam}",
      "metadata": {{
        "generated_by": "{model}",
        "generation_date": "{date}",
        "reviewed": false
      }}
    }}
  ]
}}

**IMPORTANT**: Output ONLY the JSON object. Do NOT include any text before or after the JSON.
"""


# ============================================================================
# MAIN GENERATION FUNCTION
# ============================================================================

def generate_blood_relations_questions():
    """
    Main function to generate blood relations questions
    """
    
    print("=" * 80)
    print("BLOOD RELATIONS QUESTION GENERATOR")
    print("=" * 80)
    print(f"Model: {MODEL_NAME}")
    print(f"Target: {TOTAL_QUESTIONS} questions")
    print(f"Distribution: Easy={DIFFICULTY_WEIGHTS['Easy']}%, Medium={DIFFICULTY_WEIGHTS['Medium']}%, Hard={DIFFICULTY_WEIGHTS['Hard']}%")
    print(f"Batch Size: {BATCH_SIZE}")
    print("=" * 80)
    
    # Create output directory
    os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)
    
    # Generate filenames with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(OUTPUT_BASE_DIR, f"blood_relations_questions_{timestamp}.json")
    error_log_file = os.path.join(OUTPUT_BASE_DIR, f"blood_relations_errors_{timestamp}.log")
    metadata_file = os.path.join(OUTPUT_BASE_DIR, f"blood_relations_metadata_{timestamp}.json")
    
    print(f"\nüìÅ Output Files:")
    print(f"   Questions: {output_file}")
    print(f"   Errors: {error_log_file}")
    print(f"   Metadata: {metadata_file}")
    print()
    
    # Initialize OpenAI client
    print("üîë Initializing OpenAI client...")
    client = create_openai_client(OPENAI_API_KEY)
    
    if not client:
        print("‚ùå Failed to create OpenAI client. Please check your API key.")
        return
    
    # Test connection
    test_result = test_openai_connection(client, MODEL_NAME)
    if not test_result["success"]:
        print(f"‚ùå API connection test failed: {test_result['error']}")
        return
    
    print()
    
    # Calculate batch distribution
    print("üìä Calculating batch distribution...")
    batches = calculate_batch_distribution(TOTAL_QUESTIONS, BATCH_SIZE, DIFFICULTY_WEIGHTS)
    print()
    
    # Initialize tracking variables
    all_questions = []
    total_input_tokens = 0
    total_output_tokens = 0
    total_time = 0
    successful_batches = 0
    failed_batches = 0
    start_time = time.time()
    
    # Process each batch
    for batch_info in batches:
        batch_num = batch_info["batch_num"]
        batch_total = batch_info["total"]
        batch_easy = batch_info["Easy"]
        batch_medium = batch_info["Medium"]
        batch_hard = batch_info["Hard"]
        
        print(f"{'=' * 80}")
        print(f"BATCH {batch_num}/{len(batches)}")
        print(f"{'=' * 80}")
        print(f"Generating {batch_total} questions: Easy={batch_easy}, Medium={batch_medium}, Hard={batch_hard}")
        
        # Calculate starting question ID
        start_id = len(all_questions) + 1
        
        # Build prompt
        prompt = PROMPT_TEMPLATE.format(
            batch_size=batch_total,
            easy_count=batch_easy,
            medium_count=batch_medium,
            hard_count=batch_hard,
            start_id=start_id,
            topic=TOPIC_NAME,
            reasoning_topic=REASONING_TOPIC,
            main_category=MAIN_CATEGORY,
            subject=SUBJECT,
            exam=EXAM_NAME,
            model=MODEL_NAME,
            date=datetime.now().strftime('%Y-%m-%d')
        )
        
        # Generate questions
        result = generate_questions_openai(
            client=client,
            prompt=prompt,
            model=MODEL_NAME,
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS,
            max_retries=MAX_RETRIES_PER_BATCH
        )
        
        # Handle result
        if result["success"]:
            questions = result["questions"]
            
            # Validate
            validation = validate_json_output(questions, batch_total)
            
            if validation["valid"]:
                print(f"   ‚úÖ Batch successful!")
                
                # Update question IDs to ensure consistency
                for idx, q in enumerate(questions):
                    expected_id = f"blood_relations_{start_id + idx:03d}"
                    q["question_id"] = expected_id
                
                all_questions.extend(questions)
                successful_batches += 1
                
                # Track tokens and cost
                total_input_tokens += result["tokens_input"]
                total_output_tokens += result["tokens_output"]
                total_time += result["time_taken"]
                
                cost_info = calculate_cost(
                    result["tokens_input"],
                    result["tokens_output"],
                    INPUT_COST_PER_MILLION,
                    OUTPUT_COST_PER_MILLION
                )
                
                print(f"   üí∞ Batch Cost: ${cost_info['total_cost']:.4f}")
                
            else:
                print(f"   ‚ùå Validation failed!")
                for error in validation["errors"]:
                    print(f"      ‚Ä¢ {error}")
                
                failed_batches += 1
                error_msg = f"Batch {batch_num} validation failed: {validation['errors']}"
                log_error(error_msg, error_log_file)
                
                if validation["warnings"]:
                    print(f"   ‚ö†Ô∏è  Warnings:")
                    for warning in validation["warnings"]:
                        print(f"      ‚Ä¢ {warning}")
        
        else:
            print(f"   ‚ùå Batch failed: {result['error']}")
            failed_batches += 1
            error_msg = f"Batch {batch_num} generation failed: {result['error']}"
            log_error(error_msg, error_log_file)
        
        print()
        
        # Save progress after each batch
        if all_questions:
            save_to_json(all_questions, output_file)
            print(f"   üíæ Progress saved ({len(all_questions)} questions so far)")
            print()
        
        # Wait between batches (except last one)
        if batch_num < len(batches):
            time.sleep(3)
    
    # Calculate final statistics
    end_time = time.time()
    total_generation_time = end_time - start_time
    
    total_cost_info = calculate_cost(
        total_input_tokens,
        total_output_tokens,
        INPUT_COST_PER_MILLION,
        OUTPUT_COST_PER_MILLION
    )
    
    # Create metadata
    metadata = {
        "generation_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "model_used": MODEL_NAME,
        "total_questions_requested": TOTAL_QUESTIONS,
        "total_questions_generated": len(all_questions),
        "difficulty_distribution": {
            "Easy": sum(1 for q in all_questions if q.get("difficulty") == "Easy"),
            "Medium": sum(1 for q in all_questions if q.get("difficulty") == "Medium"),
            "Hard": sum(1 for q in all_questions if q.get("difficulty") == "Hard")
        },
        "batch_configuration": {
            "total_batches": len(batches),
            "batch_size": BATCH_SIZE,
            "successful_batches": successful_batches,
            "failed_batches": failed_batches
        },
        "token_usage": {
            "input_tokens": total_input_tokens,
            "output_tokens": total_output_tokens,
            "total_tokens": total_input_tokens + total_output_tokens
        },
        "cost": {
            "input_cost": total_cost_info["input_cost"],
            "output_cost": total_cost_info["output_cost"],
            "total_cost": total_cost_info["total_cost"]
        },
        "time": {
            "total_time_seconds": round(total_generation_time, 2),
            "api_time_seconds": round(total_time, 2)
        },
        "output_files": {
            "questions": output_file,
            "errors": error_log_file,
            "metadata": metadata_file
        }
    }
    
    # Save metadata
    save_to_json(metadata, metadata_file)
    
    # Print final summary
    print("=" * 80)
    print("GENERATION COMPLETE!")
    print("=" * 80)
    print(f"‚úÖ Total Questions Generated: {len(all_questions)}/{TOTAL_QUESTIONS}")
    print(f"‚úÖ Successful Batches: {successful_batches}/{len(batches)}")
    if failed_batches > 0:
        print(f"‚ùå Failed Batches: {failed_batches}/{len(batches)}")
    print()
    print(f"üìä Difficulty Distribution:")
    print(f"   Easy: {metadata['difficulty_distribution']['Easy']}")
    print(f"   Medium: {metadata['difficulty_distribution']['Medium']}")
    print(f"   Hard: {metadata['difficulty_distribution']['Hard']}")
    print()
    print(f"üéØ Token Usage:")
    print(f"   Input: {total_input_tokens:,}")
    print(f"   Output: {total_output_tokens:,}")
    print(f"   Total: {total_input_tokens + total_output_tokens:,}")
    print()
    print(f"üí∞ Total Cost: ${total_cost_info['total_cost']:.4f}")
    print(f"   Input Cost: ${total_cost_info['input_cost']:.4f}")
    print(f"   Output Cost: ${total_cost_info['output_cost']:.4f}")
    print()
    print(f"‚è±Ô∏è  Time: {total_generation_time:.1f}s ({total_generation_time/60:.1f} minutes)")
    print()
    print(f"üìÅ Output saved to:")
    print(f"   {output_file}")
    print("=" * 80)


# ============================================================================
# ENTRY POINT
# ============================================================================

if __name__ == "__main__":
    generate_blood_relations_questions()
